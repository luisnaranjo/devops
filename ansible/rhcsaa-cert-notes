[YAML]
YAML is a mark-up language used for formatting data.
YAML is generally considered easier for humans to read.
Ansible Playbooks use YAML syntax.
YAML is composed of key-value pairs, lists and dictionaries.

LIST:
List items are designated with a single hyphen (-) and a space.
Each list item should have the same indentation.
Example:
    - colours:
     - red
     - blue
    - numbers:
     - 1
     - 2

DICTIONARIES:
Dictionaries are designated with a colon (:) and a space followed by indented key-value pairs.
Example:
    car:
      brand: MyBrand
      model: XF-D
      year: 2020

You can have dictionaries of list, list of dictionaries, and any combination.

Files open with three hyphens (---) on the first line and close with three periods (...).

It's frequently useful when working on Ansible playbooks to format input with line breaks.
The pipe and right angle bracket (| and >) may be used to allow for line breaks within YAML.
    - Pipe (|):
        It will not ignore newlines in the input.
        Example:
            ports : |
            2001
            2002

            #Interpreted as:
            2001
            2002

    - Right angle bracket (>):
        It will ignore newlines in the input.
        Example:
            ports: >
            2001
            2002

            #Interpreted as:
            2001 2002

YAML has a small set of special characters:
You must use double quotes to escape a special character.
    []
    {}
    :
    >
    |

YAML auto-convert Boolean values.
If you want a literal "Yes", you must use quotes.

Floating Point Numbers are taken as numeric unless quoted.

Hash (#) is used for comments.


[ANSIBLE]
Ansible interacts with remote hosts over SSH.
There is no Ansible agent software required.

The remote system user can be different from the system user on the control host, but Ansible will need the user's name and password in order to access remote hosts.
Typically, an 'ansible' user is configured on all Ansible managed systems, and a pre-shared key is used for authentication.

To be effective, it is often necessary for the remote user to have privileges to run commands as root.

The -k flag allows for a sudo password prompt for maximum security.
Another option is to allow sudo with no password for the ansible user.


[ANSIBLE CORE COMPONENTS]
    - Inventories.
    - Modules.
    - Variables.
    - Facts.
    - Plays.
    - Playbooks.
    - Configuration files.


[INVENTORIES]
An inventory is a list of hosts that Ansible manages.
Inventories are how Ansible can locate and run against multiple systems.
Inventories can be static or dynamic.

By default, Ansible uses /etc/ansible/hosts as its inventory, but this is configurable.
Inventory may be provided in /etc/ansible/hosts or another file using:
    ansible -i FILENAME

Inventory location may be specified as follows:
    - /etc/ansible/hosts. This is the default.
    - Specified by CLI. ansible -i FILENAME.
    - Can be set in ansible.cfg

Inventories may be formatted as an INI file or as a YAML file. File formats are interchangeable.
You can also provide a directory containing many inventory files. In this way, you can specify multiple inventory files at once.

Inventory files may simply consists of hosts, patterns, groups, and variables.
It's also possible to define groups of hosts, host or group level variables, and groups of groups within the inventory.
Hosts can be part of multiple groups.
There are a number of variables that may be used within the inventory to control how Ansible connects to and interacts with target hosts.

Patterns can be used to specify similarly named hosts.
    lab[1:2].example.com

STATIC INVENTORIES:
They are inventories with static list of hosts.
They can be specified either by INI or YAML format.
They are maintained by hand, and are easy to manage for static configuration.

DYNAMIC INVENTORIES:
Inventories generated by an executable (bash script, python script, etc).
Ansible runs the script and gets back a list of hosts.
The script returns JSON containing inventory information to STDOUT.
Dynamic inventories are good for use with cloud resources subject to sudden change.
Executable file must accept following the next parameters:
    --list
    --host HOSTNAME
Don't forget to make the file executable.
Using dynamic inventories, you can pull inventory information from the likes of:
    - A cloud provider.
    - LDAP.
    - Cobbler.
    - Other CMDB software.
Example of using dynamic inventories:
    ansible all -i dynamic.py -m ping

VARIABLES IN INVENTORIES:
Ansible recommends that variables not be defined in inventory files.
They should be stored in YAML files located relative to the inventory file.
The next directories should be present in the same directory as the inventory file:
    - group_vars: The directory for groups-variable files. Group-variable files should be named after the group they represent.
    - host_vars: The directoy for hosts-variable files. host-variable files should be named after the hostname they represent.
Files named by host or group and may end in yml or yaml.
Variable files are YAML or INI formatted files containing variable assignments.


[MODULES]
Modules are essentially tools for particular tasks.
Almost all modules take parameters.
Can be run from the command line or within a playbook.
There are a significant number of modules for many kinds of work.
They return JSON data.
Custom modules can be written (in Python).


[VARIABLES]
Variable names should be letters, numbers, and underscores.
Variables should always start with a letter.
They can be scoped by a group, a host or even in a playbook.
Typically used for configuration values and various parameters.
Variables can also be used to store the return value of executed commands.
There are a number of predefined variables used by Ansible.

PLACES TO DEFINE VARIABLES:
    - vars. Regular variables.
    - vars_file. A way to include variable files on the playbook.
    - vars_prompt. Allows you to prompt for variables at playbook execution.
    - Command line via ansible-playbook play.yml -e '{"myVar":"myValue","anotherVar":"anotherValue"}'
    - Roles.
    - Blocks.
    - Inventories.

VARIABLE USE:
For safety, always use double quoting when working with variables.
    - debug: msg="Look! I'm using my variable {{ myVar }}".

DICTIONARY VARIABLES:
Ansible variables may also be dictionaries.
YAML formatting allows for python style dictionaries to be used as variables.

Declaration:
    employee:
        name: Luis
        id: 42

There are two formats to access dictionary values:
    employee['name']    # Recommended option.
    employee.name
It's recommended to use the format with square brackets.

MAGIC VARIABLES:
Ansible defines several special variables knowns as magic variables.

You can use the variable 'hostvars' to look at facts about other hosts in the inventory.
Example:
    {{hostvars['node1']['ansible_distribution']}}

There is also a 'groups' variable that provides inventory information.
Example:
    {{groups['webservers']}}    # Will return a list of servers in the 'webservers' group.

FILTERS:
Jinja2 filters can be useful in manipulating text format.
Example:
    {{groups['webservers']|join(' ')}}


[FACTS]
Ansible facts are system properties collected by Ansible about a target host (like hostname, kernel version, etc).
Facts are discovered by Ansible automatically when it reaches out a host.

There are two ways facts are collected:
    - Using the setup module with an ad-hoc command: ansible all -m setup
    - Facts are gathered by default when playbook is executed.

The setup module can retrieve fact on a per-target basis.
Facts are collected by default on playbook execution, but this is configurable using gather_facts:[yes|no].
Facts can be cached between playbook executing. However, this is not the default behavior.

HOW TO USE FACTS:
Any collected facts can be accessed through variables: {{ ansible_default_ipv4.address }}
It's possible to use filters with regex, in ad-hoc mode, to match facts names. Example:
    ansible testserver -m setup -a "filter=*ipv4*"
Facts may also be used with conditionals to have plays behave differently on hosts that meet certain criteria.

CUSTOM FACTS:
Custom facts can be set up using the facts.d directory in the target hosts:
    - Create /etc/ansible/facts.d on target system.
    - All files ending in .fact within that directory will be available as system local facts, and returned under 'ansible_local' variable. Example of retrieving:
        ansible testserver -m setup -a "filter=ansible_local"
    - Files can be INI, JSON, or executable that returns JSON.


[PLAYS]
The goal of a play is to map a group of hosts to some well-defined roles.
A play may use one or more modules to achieve a desired end state on a group of hosts.


[PLAYBOOK]
A playbook is a series of plays.
As an example, a playbook may deploy new web servers, install a new app to existing application servers, and run SQL against some database servers to support the new application.
Ansible make use of idempotency, that means no matter how many times you run a playbook, it will only make the change once.

RETRY:
If a playbook execution fails in some hosts, Ansible will create a PLAYBOOK.retry file in the current working directory with only the list of hosts in which the playbook execution failed.

LIMIT:
When running a playbook, you can use limit to specify the execution in only one host or a group of hosts.


[CONFIGURATION FILES]
There are several possible locations you can put configurations for Ansible (The next are in order processed):
    - ANSIBLE_CONFIG (environment variable).
    - ansible.cfg (in the current working directory).
    - .ansible.cfg (in the home directory).
    - /etc/ansible/ansible.cfg
Once Ansible detects a configuration file in that order, it will stop searching.

Configuration can also be set in environment variables. This will override any config file setting.
Some commonly used settings:
    - ansible_managed. Set a message inserted into Ansible managed files.
    - forks. Set number of forks used by Ansible.
    - inventory. Change default inventory location.


[ANSIBLE AD-HOC COMMANDS USAGE]
You can run ansible either ad-hoc or as a playbook.
Both methods have the same capabilities.
An ad-hoc command is similar to a single bash command.

USE CASES:
    - Operational commands. Examples:
        * Checking log contents.
        * Daemon control.
        * Process management.

    - Informational commands. Examples:
        * Check installed software.
        * Check system properties.
        * Gathering system performance information (CPU, disk space, memory use).

    - Research. Examples:
        * Work with unfamiliar modules on test systems.
        * Practice for playbook engineering.

COMMAND:
    ansible.

EXAMPLE:
    ansible webservers -i ansible/inv.ini -b -m yum -a "name=httpd state=latest" -f 100


[PLAYBOOK USAGE]
Playbooks are effective for deployments, routine tasks, system deployment.
Playbooks are similar to bash scripts.

COMMAND:
    ansible-playbook.


[REGISTER]
Register is a keyword that saves results of a command to a variable.
You can use variables to retrieve the results of running commands.
    register: var   #var is the variable name in which the data is stored.
The variable can be referenced within the play.
    It returns many attributes, but it can be set to display only certain values.

Several attributes are available, including 'return code', 'stderr', and 'stdout'.

    The contents of the variable may be output using the 'debug' module or may be used with conditionals to make runtime decisions.

Example:
    ---
    - hosts: localhost
      tasks:
        - name: Create a file.
          file: state=touch path=/home/user/testfile
        - name: Edit file.
          lineinfile:
            line: "Demo in progress."
            path: /home/user/testfile
          register: info
        - debug: msg="{{ info }}"


[CONDITIONALS & LOOPS IN CONTROL PLAY EXECUTION]
HANDLERS:
Handlers are tasks that may be flagged to run using the 'notify' keyword.
The 'notify' keyword will only flag the handler if a task block make changes.
The calls made in the notify section correspond to the handler definitions in the play setup.
'Listen' is a keyword that sets a value that may be used to call a handler as well. Example:
    listen: web handler
Usage of notify:
    notify: "web handler"

CONDITIONALS:
Conditional uses Jinja2 expressions to control playflow.
The 'when' keyword allows for conditional tasks.
It's also possible to define changed conditions using the 'changed_when' keyword.
Example:
    ---
    - hosts: testservers
      tasks:
        - name: "Shutdown Debian flavored systems."
          command: /sbin/shutdown -t now
          when: ansible_os_famility == "Debian"
          # You can also use list notation.
          # when:
          # - ansible_hostname == "Debian"

LOOPS:
'with_items' loop through a task for each object provided.
The {{ item }} variable is used for each iteration of the loop.
There is also a with_files keyword that iterates through files.
Loops are affiliated with individual tasks, however, a task may be an include directive containing several tasks. This allows for looping over many tasks.
Example:
    ---
    - hosts: localhost
      tasks:
        - name: Download files.
          get_url:
            url: "http://files.example.com/{{ item }}"
            dest: "/home/ansible/files/{{ item }}"
          with_items:
            - file1
            - file2
            - file3


[ERROR HANDLING]
IGNORE_ERRORS:
When 'ignore_errors' is set for a task, playbooks will not halt on that task failing.

FAILED_WHEN (FAILURE CONDITIONAL):
'failed_when' allows you to specify the failure condition for a given task if necessary.

BLOCK:
'block' groups are used to have Ansible attempt a task and take action depending on the success or failure of that task.
It's similar to a try/catch block in programming languages.
The 'rescue' block runs on a failure.
The 'always' block (this block is optional) always runs.
Example:
    ---
    - hosts: localhost
      tasks:
        - name: Download file.
          block:
            - get_url:
              url: http://files.example.com/transaction_list
              dest: /home/ansible/transaction_list
            - debug: msg="File downloaded"
          rescue:
            - debug: msg="File site appears to be down. Try again later."
          always:   # Always section is optional.
            - debug: msg="Attempt completed".


[TAGS]
It is possible to run specific tasks in playbooks using 'tags'.
Each task may have one or more tags.

Tags may be provided when ansible-playbook runs using the '--tags' flag which will have Ansible only run tasks that are tagged as specified.
Conversely, '--skip-tags' may be used with ansible-playbook command to skip plays that match provided tags.

Command example:
    ansible-playbook playbook.yaml --tags installation

Playbook example:
    ---
    - hosts: localhost
      become: yes
      tasks:
        - name: Download files.tgz
          get_url:
            url: http://files.example.com/files.tgz
            dest: /mnt/files.tgz
          tags:
            - download
        - name: Unarchive files.tgz
          unarchive:
            src: /mnt/files.tgz
            dest: /mnt/
          tags:
            - unarchive


[TEMPLATES]
Templates are jinja 2 template files with Ansible variables inside that are substituted on play execution.
Templates give the ability to provide a skeletal file that can be dynamically completed using variables.
The most common template use case is configuration management.
Templates are generally used by providing a template file on the ansible control node, and then using the template module within your playbook to deploy the file to a target server or group.

Template files use the .j2 file extension (for jinja 2). And are processed using the Jinja2 template language.
Template files have access to the same variables that the play that calls them does.

Templates are deployed using the 'template' module.

TEMPLATE FILES:
The next is an example of a template file for an htaccess config file:
    AuthUserFile {{ auth_user_file }}
    AuthGroupFile /dev/null
    AuthName "{{ auth_text }}"
    AuthType Basic
    require valid-user
    require user {{ secure_user }}

Note that the values in double curly braces are Ansible variables that will be substituted when the template is deployed.
Other texts will be left unchanged by the template module.

TEMPLATE USAGE IN PLAYBOOKS:
An example of the template module used in a playbook:
    ---
    - hosts: webservers
      tasks:
        - name: Ensure Apache is at the latest version.
          yum: name=httpd state=latest
        - name: Write the apache config file.
          template: src=/srv/httpd.j2 dest=/etc/httpd.conf


[ROLES]
Roles provide a way of automatically loading certain var_files, tasks, and handlers based on a known file structure.
Roles also make sharing of configuration templates easier.
Roles require a particular directory structure, and at least one of the directories must exist and contain a 'main.yml'.
Unused directories need not exist.

Ansible checks for finding roles in the following places:
    - $PWD/roles.
    - /etc/ansible/roles.

VARIABLES:
Variables defined within a role (using the defaults or vars directories) may be accessed across roles.
Role handlers has the same behavior.
You may still pass variables on the command line with the '-e' flag for use in a role. (These variables override all others in terms of precedents).
Best practice dictates that you properly namespace your variables when working with a role to avoid conflicts.

NESTING:
Roles may include other roles using the dependencies keyword.
Dependent roles are applied prior to the role dependent on them.
A role using the same parameters will not be applied more than one time.
This can cause complication with role dependencies.
Having 'allow_duplicates: true' defined in 'meta/main.yml' within a role will allow the role to be applied more than once.

ROLE DIRECTORY STRUCTURE:
sample_role/
├─ tasks/
├─ handlers/
├─ vars/
├─ defaults/
├─ files/
├─ templates/
└─ meta/

DIR TASKS:
The tasks directory contains the main list of tasks to be executed by the role.
This directory must include a 'main.yml' if that directory is being used.
You can think of 'main.yml' as the entry point for the tasks section of the role.

DIR HANDLERS:
The handlers directory contains handlers, which may be used by the role or even anywhere outside of this role.
The directory is entered via a 'main.yml' within the directory.
More on handlers:
    - Handlers are essentially tasks that may be flagged to run using the 'notify' keyword.
    - The 'notify' keyword will only flag the handler if a task block makes changes.
    - A handler will only be triggered once even if they are notified by multiple tasks.

DIR VARS:
The vars directory contains variables used within the role.
The vars directory is entered via a 'mail.yml'.
The vars directory is one of three primary ways to interact with variables within a role (aside from convectional variable use such as inventory).
The other two ways are:
    - Using the 'defaults' directory.
    - Passing parameters to the role.
The vars directory has the highest level of precedence. It will override inventory variables as well.
The vars directory may only be overridden by variables passed via CLI.

DIR DEFAULTS:
The defaults directory contains default variables for the role.
The defaults directory is entered via a 'main.yml'.
The defaults directory is one of three primary ways to interact with variables within a role (aside from convectional variable use such as inventory).
The other two ways are:
    - Using the 'vars' directory.
    - Passing parameters to the role.
The defaults directory is only meant to provide value to a variable if no other value is given.

DIR FILES:
The files directory contains files which can be deployed via the role.
Files within this directory may be referenced without path throughout the role.
Note this directory is for ordinary files (not var files or templates).

DIR TEMPLATES:
The templates directory contains templates which can be deployed via this role.
Templates within this directory may be referenced without a path throughout the role.

ROLE USE:
General:
    ---
    - hosts: webservers
      role: apache
Another general example:
    ---
    - hosts: webservers
      tasks:
        - include_role:
            name: apache
          tags:
            - RH_HTTPD
          when: "ansible_os_famility == 'RedHat'"

Using parameters:
    ---
    - hosts: webservers
      roles:
        - common
        - role: foo_app_instance
          vars:
            dir: '/opt/a'
            app_port: 5000
        - role: foo_app_instance
          vars:
            dir: '/opt/b'
            app_port: 5001

Using dependencies:
    ---
    dependencies:
        - role: common
          vars:
            some_parameter: 3
        - role: apache
          vars:
            apache_port: 80


[ANSIBLE GALAXY]
Ansible galaxy is essentially a large public repository of Ansible roles.
Roles ship with readmes detailing role use and available variables.
Galaxy contains a large number of roles that are constantly evolving and increasing.
Galaxy can use git allowing for other role sources such as GitHub.

COMMAND ansible-galaxy:
Ansible ships with the 'ansible-galaxy' command which may be used to install roles from Galaxy among other useful role management features.

'ansible-galaxy' can also create new empty roles in your working directory like so:
    ansible-galaxy init ROLENAME

You can download roles from galaxy.ansible.com via the command:
    ansible-galaxy install USERNAME.ROLE

Roles installed in the 'roles_path' may be listed using:
    ansible-galaxy list

Another useful subcommands of ansibe-galaxy are:
    - remove.
    - search.
    - login.

The '-p' flag allows specification of local role location. 'ansible-galaxy' uses /etc/ansible/roles by default.


[PARALLELISM]
It's possible to control the number of hosts acted upon at once time by Ansible.
The Ansible process will create forks to execute actions in parallel.
By default, the process will only fork 5 times.
The number of forks can be set for a single command using '-f' flag with either the 'ansible' or 'ansible-playbook' commands.
The default may be changed in 'ansible.cfg' file.
The 'serial' keyword may also confine the number of simultaneous updates within a playbook.


[ANSIBLE VAULT]
The 'ansible-vault' command allows file encryption, and requires a password to un-encrypt.
    ansible-vault encrypt FILE

The 'ansible-vault rekey' command will allow you to re-encrypt a file and reset the password (You will need to know the original password).

To supply the vault password during play execution, you must use either the 'ask-vault-pass' or '--vault-password-file' flags.

Ansible 2.4 introduces the --vault-id feature.

It is also possible to set 'no_log' within a playbook (a tasks) to censor sensitive log output.
    no_log: true


[ANSIBLE TOWER]
Ansible Tower provides a web server interface to Ansible.
System requirements are somewhat heavy.
Tower is only free for minimal use. Working with more than a few systems requires a paid license.
The two key benefits of Ansible Tower are:
    - User permissioning.
    - Audit trail (only provided with license).
It's only touched on in EX407 exam.

When installing Ansible Tower, the first step is to check the readme.md

The Ansible Tower configuration file is: /etc/tower/settings.py


[DOCUMENTATION]
The 'ansible-doc' binary ships with Ansible and is capable of providing documentation on each Ansible module.
You can use the '--list' flag to get all available modules.
Syntax:
    ansible-doc MODULE      # Gets details on a specific module.
    ansible-doc -s MODULE   # Gets a condensed listing of a module's function.

The list of all Ansible modules in the online documentation is in the 'Module Index' section.
Online documentation page: docs.ansible.com

Using 'ansible-doc --list' command, it may take a while to provide information.


[CONFIGURING THE ANSIBLE INITIAL ENVIRONMENT]
INSTALLING AND CONFIGURING AN ANSIBLE CONTROL NODE:
Installing the package and configuring infra:
    - Run command to install Ansible:
        sudo yum install ansible
    - Run command to create the 'ansible' user:
        sudo useradd ansible
    - Run command to set the 'ansible' user password:
        sudo passwd ansible
    - Run command to provide elevated permissions to 'ansible' user without password needed.
        sudo visudo
        Line: ansible   ALL=(ALL)   NOPASSWD: ALL

Setting the host inventory (static):
    - Run command to add the controlled host information (hostname and IP).
        vim /etc/hosts
        Line: Depending on the scenario.
    - Run command to add the controlled nodes into the Ansible default inventory file.
        vim /etc/ansible/hosts
        Line: Depending on the scenario.

CONFIGURING ANSIBLE-MANAGED NODES:
Configure users & privilege escalation on managed nodes:
    - On the client servers run command to create 'ansible' user:
        useradd ansible
    - On the client servers run command to set password for the 'ansible' user:
        passwd ansible
    - On the client servers run command to provide elevated permissions to 'ansible' user without password needed.
        sudo visudo
        Line: ansible   ALL=(ALL)   NOPASSWD: ALL

DISTRIBUTE SSH KEYS TO MANAGED NODES:
    - On the control node, run the next command to create the ssh keys:
        su - ansible    # As the 'ansible' user.
        ssh-keygen      # Generate the key.
    - Copy the generated key into the controlled nodes.
        ssh-copy-id CLIENTSERVER    # CLIENTSERVER will be the controlled node(s). You will need to do this for 'localhost' too if needed.

VALIDATE A WORKING CONFIGURATION USING AD-HOC ANSIBLE COMMANDS:
    - Run the next commands form the control node to verify everything is set correctly:
        ansible all -m ping         # To test connectivity.
        ansible all -b -m ping      # To test the elevated permissions.


[FIREWALL RULES]
Ansible and firewall rules.
There are Ansible modules that can be used with firewalls:
    - firewalld: The firewalld module like others, can be used to add or remove rules.
    - iptables: The iptables module can also be used for firewall rules.


[SECURITY]
Ansible is very useful as a security tool.
You can make security changes to many nodes at once.
You can apply changes to help with easily securing nodes.
You can check lots of nodes for vulnerability quickly.
It can work well with other tools that you may have in place.
Not just for Linux; it can be used for OS X, Solaris, Windows, and others.
Can be used or devices such as NetApp or EMC storage, F5, and others.

There are many modules that can be useful for security:
    - selinux: Configures the SELinux mode and policy.
    - firewalld and iptables: Both manage firewall policies.
    - pamd: Manages PAM modules.
Capable of working with Datalog, Nagios, and other monitoring tools.
Manage users and groups.
Can manage certificates such as OpenSSL or SSH.


[COMMON MODULES]
This is the list of the most common ansible modules.

PING:
Validate server is up and reachable.
No required parameters.

SETUP:
Gather ansible facts.
No required parameters.

YUM:
Use yum package manager.
Needed parameters:
    - name.
    - state.

SERVICE:
Control daemons.
Needed parameters:
    - name.
    - state.

USER:
Manipulate system users.
Needed parameters:
    - name.

COPY:
Copy files.
Able to change ownership and permissions in the process of the copy.
Needed parameters:
    - src.
    - dest.

FILE:
Work with files.
Needed parameters:
    - path.

GIT:
Interact with git repositories.
Needed parameters:
    - repo.
    - dest.


[PING MODULE]
Validate Ansible can interact with a host.
COMMON PARAMETERS:
None.


[YUM MODULE]
Interact with yum package manager.
COMMON PARAMETERS:
    - name. Name of the package.
    - state. Package state on a given system:
        * version: Ensures the version of the package is present in the system (latest value for latest package version).
        * installed: Ensures the package is installed in the system.
        * absent: Ensures the package is not installed in the system.


[FILE MODULE]
Work with system files.
COMMON PARAMETERS:
    - name. File to operate on.
    - state.
        * touch: Create new.
        * absent: Deleted.
        * directory: Create directory.
        * link: Symbolic Link.
    - mode. POSIX file permissions (XXXX).
    - owner. File user owner.
    - group. File group owner.
    - setype. SELinux File Context.


[LINEINFILE MODULE]
Place or remove line from a file based on regular expressions.
COMMON PARAMETERS:
    - path. File to change.
    - line. The text to add.
    - regexp. A regular expression used to insert line or the line to remove.
    - state.
        * absent: Remove line.
        * present: Add line.


[COPY MODULE]
Copy files to target hosts.
COMMON PARAMETERS:
    - src. File (on localhost) to copy.
    - dest. Destination to place file copy (on target host).
    - content. Use in place of src to write content into a new file (as opposed to copy).
    - owner. Destination file user owner.
    - group. Destination file group owner.
    - mode. POSIX destination file permissions.


[SERVICE MODULE]
Control system daemons.
COMMON PARAMETERS:
    - name. Service with which to interact.
    - state. Service state:
        * started.
        * stopped.
        * restarted.
    - enabled. Service boot configuration:
        * yes.
        * no.


[GET_URL MODULE]
Download an artifact from a web server.
COMMON PARAMETERS:
    - url. URL from which to download artifact.
    - dest. Filepath and name for downloaded file copy.


[ARCHIVE MODULE]
Work with file archives.
Assumes the compression source exists on the target.
Does not copy source files from the local system to the target before archiving.
You can delete source files after archiving by using the 'remove=true' option.
COMMON PARAMETERS:
    - path. File path to archive.
    - dest. The newly created archive.


[UNARCHIVE MODULE]
Work with file archives.
If a 'checksum' is required, then use the 'get_url' or 'uri' instead.
By default it will copy from the source file to the target before unpacking.
COMMON PARAMETERS:
    - src. The archive to be unarchive.
    - dest. The unarchive files.
    - remote_src. If this is set to 'yes' it will look for the archive file (specified with 'src' path) in the remote node, not in the local control node.


[SETUP MODULE]
Gather and return Ansible facts.
COMMON PARAMETERS:
None.


[USER MODULE]
Create and manage system users.
COMMON PARAMETERS:
    - name. User name.
    - state.
        * present.
        * absent.
    - group. user's primary group.
    - uid. Set uid for a user.


[TEMPLATE MODULE]
The template module is used to deploy template files.
The template module has several useful parameters.
COMMON PARAMETERS:
    - src. The template to use (in the control node).
    - dest. Where the resulting file should be on the target host.
    - validate. A command that will validate the file before deployment. The path to the file to validate is passed in via '%s'.
There are also parameters for manipulating file properties such as 'owner', 'group', and 'mode'.


[COMMAND & SHELL MODULES]
They run system commands on a target system.
Command module doesn't set up any kind of environment prior to execution.
Shell module will set up a login shell prior to execution.
COMMON PARAMETERS (for both):
    - creates. A file name which if it exists, the command will not be run.
    - removes. A file name which, if it does not exists, the command will not be run.


[REPLACE MODULE]
Replace all instances of a particular string in a file using a back-referenced regular expression.
COMMON PARAMETERS:
    - path. File to modify
    - regexp. Regular expression pattern to match.
    - replace. Value used to replace matched pattern.


[CRON MODULE]
The 'cron' module is used to manage 'crontab' on your nodes.
You can create environment variables as well as named crontab entries.
You can add, update, and delete entries.
You should add a 'name' with the crontab entry so it can be removed easily with a playbook.
When managing environment variables, no comment line gets added. However, the module uses the 'name' parameter to find the correct definition line.
You can add a specific user if you need to set a crontab entry for a user (need to become 'root').
COMMON PARAMETERS:
    - name: Specify the name of an entry.
                name: "Job 001"
    - state: Represent the state of the crontab entry.
        * absent: Ensures it's removed/absent.
        * present: Ensures it's added/present.
    - disabled: Comment out a crontab entry (only works if 'state=present').
    - special_time: Special time specification nickname.
        * reboot: Set the crontab entry to run at reboot if required.
    - insertafter: Specify to add the crontab entry after another entry.
    - insertbefore: Specify to add the crontab entry before another entry.


[AT MODULE]
The 'at' command is used in Linux to schedule jobs that will be running once in the future.
It's used for single ad-hoc jobs and is not meant as a replacement for 'cron'.
It's part of a group of commands that get installed with the 'at' software.
The other commands are:
    - at: Execute commands at a specific time.
    - atq: Lists the user pending jobs.
    - atrm: Deletes a job by its job number.
    - batch: Executes the command depending on specific system load levels. A value must be specified.
Only 'at' and 'atrm' are controlled via the 'at' module.
It may not be on all systems. Verify its installation.
On Red Hat or CentOS systems it's installed via:
    yum install at
The service is controlled via the 'atd' daemon.
COMMON PARAMETERS:
    - command: The command to execute.
    - count: The amount of units for time in the future.
    - units: The unit related to the 'count' value.
        * minutes.
        * hours.
        * days.
        * weeks.


[SELINUX MODULE]
The selinux module configures the SELinux mode and policy.
A reboot may be required after usage.
Ansible will not issue this reboot but will let you know when it is required.
REQUIREMENTS:
The below requirements are needed on the host that executes this module.
    libselinux-python
COMMON PARAMETERS:
    - policy: The name of the SELinux policy to use will be required if state is not 'disabled'.
        * targeted.
    - state: The SELinux mode. Required.
        * disabled.
        * enforcing.
        * permissive.


[COMMANDS]
ssh-keygen                      # Generated the SSH keys.
ssh-copy-id REMOTE_HOST         # Copy the public ssh key of the current user from the current host to REMOTE_HOST.


[MISCELLANEOUS]
/etc/ansible/hosts      # Default inventory file.
/etc/ansible/roles      # Default roles directory.

COMMAND ansible:
When running an ad-hoc command, if no inventory is specified (-i INVENTORY_FILE), the default inventory is used.
When running an ad-hoc command, you can specify to change the user for the command you are running via the -b flag (-b USER). If no user specified when using the -b flag, then root user is implied.
When running an ad-hoc command, you can specify the module to be used via the -m flag (-m MODULE).
When running an ad-hoc command, you can specify the arguments for the specified module via the -a flag (-a "PROPERTY=VALUE PROPERTY=VALUE").
The -a flag can be used without -m to run a shell command. EXAMPLE:
    ansible webservers -a "touch /tmp/newfile"
The number of forks can be set for a single command using '-f' flag with either the 'ansible' or 'ansible-playbook' commands.

COMMAND ansible-playbook:
When running an ad-hoc command, you can specify the module to use parallelism via the fork flag -f (-f NUMBER). The NUMBER represents at how many servers the ansible command will run at the same time.
When running an ansible-playbook command, you can specify the flag --limit to limit the servers in which the playbook will be applied (--limit SERVER)
When running an ansible-playbook command, you can specify the flag --tags to tell Ansible to only run the tasks related to the specified tag.
When running an ansible-playbook command, you can specify the flag --skip-tags to tell Ansible to only run the tasks that are not related to the specified tag.
When running an ansible-playbook command, you can specify the flag -e to specify additional variables. If you are working with variable files, specify the file with a '@' preceding it. EXAMPLE:
    ansible-playbook play.yml -e '{"myVar":"myValue","anotherVar":"anotherValue"}'
    ansible-playbook play.yml -e "@VARFILE"         # Using a variable file.
The number of forks can be set for a single command using '-f' flag with either the 'ansible' or 'ansible-playbook' commands.

To supply the vault password during play execution, you must use either the 'ask-vault-pass' or '--vault-password-file' flags.
Ansible 2.4 introduces the --vault-id feature.

COMMAND ansible-galaxy:
ansible-galaxy init ROLENAME            # Creates new empty roles in your working directory
ansible-galaxy install USERNAME.ROLE    # Downloads roles from galaxy.ansible.com. By default it places them in the default roles directory.
ansible-galaxy list                     # List all roles installed in the 'roles_path'.
Another useful subcommands of ansible-galaxy are:
    - remove.
    - search.
    - login.
The '-p' flag allows specification of local role location. 'ansible-galaxy' uses /etc/ansible/roles by default.

COMMAND ansible-vault:
ansible-vault encrypt FILE                      # Encrypts a file (requires a password to un-encrypt).
ansible-vault rekey FILE                        # Re-encrypts a file and reset the password.
ansible-vault encrypt_string 'STRING' -n NAME   # Will encrypt and format a provided string(in STDOUT) into a format that can be included in ansible-playbook YAML files.
                                                # --vault-id (Since Ansible 2.4) can be used to indicate which vault ID ('dev', 'test', 'cloud', etc.) a password is for as well as how to source the password(prompt, a file path, etc).
ansible-vault view FILE                         # Lets you view the content of a encrypted file.
ansible-vault edit FILE                         # Lets you work with an encrypted file (Pops out the default editor to change the file).
ansible-vault decrypt FILE                      # Decrypts an encrypted file.
